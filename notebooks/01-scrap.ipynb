{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "import json\n",
    "\n",
    "from typing import Literal, Any\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "HOST = \"https://gestiona7.madrid.org\"\n",
    "FILENAME_SUMMON = \"nsus_rest_ares/v1/SustInterinos/citados\"\n",
    "FILENAME_ASSIGN = \"nsus_rest_ares/v1/ActosPublicosSustituciones/resolucion\"\n",
    "\n",
    "URL_SUMMON = f\"{HOST}/{FILENAME_SUMMON}\"\n",
    "URL_ASSIGN = f\"{HOST}/{FILENAME_ASSIGN}\"\n",
    "\n",
    "SECTION = \"0590\"\n",
    "SPECIALTIES = (\n",
    "    \"006\",\n",
    "    \"007\",\n",
    "    \"008\",\n",
    "    \"019\",\n",
    "    \"102\",\n",
    "    \"103\",\n",
    "    \"115\",\n",
    "    \"116\",\n",
    "    \"117\",\n",
    ")\n",
    "\n",
    "start_date = datetime.date(2022, 9, 1)\n",
    "today = datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_ares_summon(\n",
    "    list_type: Literal[\"O\", \"V\", \"E\"],\n",
    "    specialty: str,\n",
    "    date: datetime.date,\n",
    ") -> list[dict[str, Any]]:\n",
    "    fcpublico = date.strftime(\"%Y-%m-%d\")\n",
    "    cfunc = f\"{SECTION}{specialty}\"\n",
    "    itTipoActo = list_type\n",
    "    body = {\n",
    "        \"fcpublico\": fcpublico,\n",
    "        \"cfunc\": cfunc,\n",
    "        \"itTipoActo\": itTipoActo\n",
    "    }\n",
    "    response = requests.post(URL_SUMMON, json=body)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error {response.status_code} for {fcpublico} {cfunc} {itTipoActo}\")\n",
    "        return []\n",
    "    return response.json()\n",
    "\n",
    "def scrap_summon_specialty(\n",
    "    specialty: str,\n",
    "    list_type: Literal[\"O\", \"V\", \"E\"],\n",
    "    date_from: datetime.date,\n",
    "    date_to: datetime.date,\n",
    "    sleep_time: float = 0.0,\n",
    ") -> list[dict[str, Any]]:\n",
    "    total_days = (date_to - date_from).days + 1\n",
    "    dates = [date_from + datetime.timedelta(days=i) for i in range(total_days)]\n",
    "    \n",
    "    data = []\n",
    "    for date in dates:\n",
    "        date_data = scrap_ares_summon(list_type, specialty, date)\n",
    "        data.extend(date_data)\n",
    "        sleep(sleep_time)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def scrap_summon_list(\n",
    "    list_type: Literal[\"O\", \"V\", \"E\"],\n",
    "    date_from: datetime.date,\n",
    "    date_to: datetime.date,\n",
    "    sleep_time: float = 0.0,\n",
    ") -> list[dict[str, Any]]:\n",
    "    data = []\n",
    "    for specialty in SPECIALTIES:\n",
    "        specialty_data = scrap_summon_specialty(specialty, list_type, date_from, date_to, sleep_time)\n",
    "        data.extend(specialty_data)\n",
    "    return data\n",
    "\n",
    "def scrap_summon_list_to_json(\n",
    "    list_type: Literal[\"O\", \"V\", \"E\"],\n",
    "    date_from: datetime.date,\n",
    "    date_to: datetime.date,\n",
    "    filename: str,\n",
    "    sleep_time: float = 0.0,\n",
    ") -> None:\n",
    "    data = scrap_summon_list(list_type, date_from, date_to, sleep_time)\n",
    "    with Path(filename).open(\"w\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrap_summon_list_to_json(\"O\", start_date, today, f\"data/raw/summon-O.json\", 0.0)\n",
    "scrap_summon_list_to_json(\"V\", start_date, today, f\"data/raw/summon-V.json\", 0.0)\n",
    "scrap_summon_list_to_json(\"E\", start_date, today, f\"data/raw/summon-E.json\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_ares_assign(\n",
    "    list_type: Literal[\"O\", \"V\", \"E\"],\n",
    "    specialty: str,\n",
    "    date: datetime.date,\n",
    ") -> list[dict[str, Any]]:\n",
    "    fcpublico = date.strftime(\"%Y-%m-%d\")\n",
    "    cfunc = f\"{SECTION}{specialty}\"\n",
    "    ittipoacto = list_type\n",
    "    body = {\n",
    "        \"fcpublico\": fcpublico,\n",
    "        \"cfunc\": cfunc,\n",
    "        \"ittipoacto\": ittipoacto\n",
    "    }\n",
    "    response = requests.post(URL_ASSIGN, json=body)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error {response.status_code} for {fcpublico} {cfunc} {ittipoacto}\")\n",
    "        return []\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def scrap_assign_specialty(\n",
    "    specialty: str,\n",
    "    list_type: Literal[\"O\", \"V\", \"E\"],\n",
    "    date_from: datetime.date,\n",
    "    date_to: datetime.date,\n",
    "    sleep_time: float = 0.0,\n",
    ") -> list[dict[str, Any]]:\n",
    "    print(f\"Scraping {specialty} {list_type} {date_from} {date_to}\")\n",
    "    total_days = (date_to - date_from).days + 1\n",
    "    dates = [date_from + datetime.timedelta(days=i) for i in range(total_days)]\n",
    "    \n",
    "    data = []\n",
    "    for date in dates:\n",
    "        date_data = scrap_ares_assign(list_type, specialty, date)\n",
    "        data.extend(date_data)\n",
    "        sleep(sleep_time)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def scrap_assign_list(\n",
    "    list_type: Literal[\"O\", \"V\", \"E\"],\n",
    "    date_from: datetime.date,\n",
    "    date_to: datetime.date,\n",
    "    sleep_time: float = 0.0,\n",
    ") -> list[dict[str, Any]]:\n",
    "    data = []\n",
    "    for specialty in SPECIALTIES:\n",
    "        specialty_data = scrap_assign_specialty(specialty, list_type, date_from, date_to, sleep_time)\n",
    "        data.extend(specialty_data)\n",
    "    return data\n",
    "\n",
    "def scrap_assign_list_to_json(\n",
    "    list_type: Literal[\"O\", \"V\", \"E\"],\n",
    "    date_from: datetime.date,\n",
    "    date_to: datetime.date,\n",
    "    filename: str,\n",
    "    sleep_time: float = 0.0,\n",
    ") -> None:\n",
    "    data = scrap_assign_list(list_type, date_from, date_to, sleep_time)\n",
    "    with Path(filename).open(\"w\") as f:\n",
    "        json.dump(data, f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wtf\n",
      "Scraping 006 O 2022-09-01 2023-02-26\n"
     ]
    }
   ],
   "source": [
    "scrap_assign_list_to_json(\"O\", start_date, today, f\"data/raw/assign-O.json\", 0.0)\n",
    "scrap_assign_list_to_json(\"V\", start_date, today, f\"data/raw/assign-V.json\", 0.0)\n",
    "scrap_assign_list_to_json(\"E\", start_date, today, f\"data/raw/assign-E.json\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrap-ares-FzfA0gbl-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56c291a1fdef50ea4fbe774c7df27b68fe1d8f1a8750be1683ecd1affd5a4f6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
